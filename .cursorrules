# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

## Tools

Note all the tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

IMPORTANT: Make better use of the available Python tools! Before diving into implementation, always try to:

1. Use search_engine.py to research solutions and best practices
2. Use web_scraper.py to gather detailed documentation
3. Use llm_api.py for complex analysis tasks
4. Combine tools for a better research workflow

Remember: These tools are here to help make better informed decisions. Use them proactively!

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following tools are available:

- Screenshot Capture:

'''bash
python tools/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
'''

- LLM Verification with Images:

'''bash
python tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
'''

Example workflow:

'''python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

## Take a screenshot

screenshot_path = take_screenshot_sync('<https://example.com>', 'screenshot.png')

## Verify with LLM

response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
'''

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:

'''bash
python ./tools/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
'''

The LLM API supports multiple providers:

- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.

'''bash
python ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
'''

This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.

'''bash
python ./tools/search_engine.py "your search keywords"
'''

This will output the search results in the following format:

'''bash
URL: <https://example.com>
Title: This is the title of the search result
Snippet: This is a snippet of the search result
'''

If needed, you can further use the `web_scraper.py` file to scrape the web page content.

## Lessons

### Core Lessons

- Use proper TypeScript types and interfaces for better type safety
- When adapting authentication systems, ensure proper session and user type compatibility
- Keep audit events consistent with the system's event types
- Handle rate limiting and security at the adapter level
- Implement proper error handling and audit logging
- Follow HIPAA compliance requirements for authentication and audit trails
- Make better use of available Python tools for research and automation:
  - Use search_engine.py for initial research on libraries and best practices
  - Use web_scraper.py for gathering detailed documentation
  - Use llm_api.py for analyzing complex technical decisions
  - Combine tools for a more thorough research workflow

### Recent Fixes

- Fixed PocketBase adapter type issues:
  - Moved PocketBase-specific interfaces to the adapter file
  - Updated audit event types to match system requirements
  - Fixed session user initialization
  - Improved type safety in authentication flow
  - Added proper error handling and audit logging

- Improved research workflow:
  - Started using search_engine.py more consistently
  - Combined search results with web_scraper.py for deeper analysis
  - Better utilization of Python toolkit for research tasks

- Fixed PostgreSQL statistics views and column names:
  - Use pg_stat_user_tables for table statistics (n_live_tup, n_dead_tup, etc.)
  - Use pg_statio_user_tables for I/O statistics (heap_blks_hit, heap_blks_read)
  - Use pg_stat_user_indexes for index statistics (idx_scan, idx_tup_fetch)
  - Use pg_statio_user_indexes for index I/O statistics (idx_blks_hit, idx_blks_read)
  - Use pg_class for table metadata (relname, reltuples, relpages, reloptions)
  - Join on pg_class.oid = pg_stat_user_tables.relid for correct table matching

### Best Practices

- Use appropriate caching strategies for different data types
- Implement proper monitoring from the start
- Follow progressive enhancement principles
- Consider both vertical and horizontal scaling
- Use correct PostgreSQL system catalog views and column names for statistics gathering
- Properly handle table and index statistics for performance monitoring
- Use appropriate joins between system catalog tables for accurate metadata

## Scratchpad

### Current Task: Performance Optimization

Progress:
[X] Initial Assessment
  [X] Review monitoring implementation
  [X] Check caching strategies
  [X] Analyze load balancing
  [X] Review error handling
  [X] Check metrics collection

[X] Performance Monitoring
  [X] Basic monitoring setup
  [X] Error tracking
  [X] Performance metrics
  [X] Advanced analytics
  [X] Custom dashboards
  [X] Alerting system

[X] Caching Strategies
  [X] Redis integration
  [X] TTL management
  [X] Pattern invalidation
  [X] Smart caching
  [X] Predictive caching
  [X] Cache warming
  [X] Cache analytics

[X] Load Balancing
  [X] Basic round-robin
  [X] Load-aware routing
  [X] Health checks
  [X] Circuit breaking
  [X] Failover handling

[X] Next Steps
  [X] Implement smart caching
    [X] Add predictive caching
    [X] Implement cache warming
    [X] Add cache analytics
    [X] Create cache optimization
  [X] Enhance load balancing
    [X] Add load-aware routing
    [X] Implement health checks
    [X] Add circuit breaking
    [X] Create failover handling
  [X] Complete monitoring
    [X] Add custom dashboards
    [X] Implement alerting
    [X] Create analytics
    [X] Add reporting

### Findings

1. Monitoring Infrastructure
   - Comprehensive metrics collection ✅
   - Performance tracking ✅
   - Error monitoring ✅
   - Custom dashboards implemented ✅
   - Real-time alerting added ✅

2. Caching System
   - Redis-based caching ✅
   - Pattern invalidation ✅
   - TTL management ✅
   - Smart caching implemented ✅
   - Predictive caching added ✅
   - Cache warming implemented ✅

3. Load Balancing
   - Load-aware routing implemented ✅
   - Health checks added ✅
   - Circuit breaking implemented ✅
   - Failover handling added ✅
   - Weighted routing strategy ✅

### Recent Implementations

1. Smart Cache Service
   - Pattern-based prediction
   - Access history tracking
   - Hot/cold key categorization
   - Cache warming
   - TTL optimization
   - Analytics and monitoring

2. Load Balancer Service
   - Health monitoring
   - Circuit breaking
   - Failover mechanisms
   - Weighted load-aware routing
   - Node metrics tracking

3. Dashboard Service
   - Real-time metrics collection
   - Custom performance dashboards
   - Alert management system
   - Historical data tracking
   - System health monitoring

### Next Actions

All planned performance optimization tasks have been completed. The system now has:

1. Smart caching with predictive warming
2. Load-aware routing with health checks and failover
3. Comprehensive monitoring with real-time alerts
4. Custom dashboards for system metrics

Would you like to proceed with any other enhancements or move on to a different area of the project?

### Dependencies

- Redis 7.x
- Node.js 18.x
- TypeScript 5.x
- Next.js 14.x

### Recent Implementations 1

1. Smart Cache Service
   - Pattern-based prediction
   - Access history tracking
   - Hot/cold key categorization
   - Cache warming
   - TTL optimization
   - Analytics and monitoring

2. Load Balancer Service
   - Health monitoring
   - Circuit breaking
   - Failover mechanisms
   - Weighted load-aware routing
   - Node metrics tracking

### Completed Tasks

1. Implemented comprehensive error handling system
2. Created distributed session management
3. Enhanced message stream component
4. Added monitoring and metrics collection

### Lessons Learned

- Proper error boundary implementation is crucial for React applications
- Distributed systems require careful state management
- Redis pub/sub is effective for real-time updates
- Error handling should be consistent across the application
- Proper loading states improve user experience

### Best Practices 1

- Use error boundaries for component-level error handling
- Implement proper fallback UI components
- Add comprehensive error logging
- Use distributed locking for shared resources
- Implement proper cleanup in distributed systems

### Recent Fixes 1

- Implemented error handling system
- Added distributed session management
- Enhanced message stream component
- Improved loading states
- Added retry mechanism

### Next Steps

1. Implement remaining UI components
2. Add comprehensive testing
3. Optimize performance
4. Add monitoring and logging
5. Create deployment pipeline

### Core Lessons 2

- Use proper TypeScript types
- Ensure proper session handling
- Keep audit events consistent
- Handle rate limiting at adapter level
- Implement proper error handling
- Follow HIPAA compliance requirements

### Recent Fixes 3

- Implemented chat system core
- Added encryption service
- Set up edge runtime
- Integrated with ZK system
- Added proper error handling

### Best Practices 3

- Use proper monitoring
- Track message metrics
- Analyze chat patterns
- Implement maintenance tasks
- Handle scaling appropriately
