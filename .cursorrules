# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

## Tools

Note all the tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

IMPORTANT: Make better use of the available Python tools! Before diving into implementation, always try to:

1. Use search_engine.py to research solutions and best practices
2. Use web_scraper.py to gather detailed documentation
3. Use llm_api.py for complex analysis tasks
4. Combine tools for a better research workflow

Remember: These tools are here to help make better informed decisions. Use them proactively!

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following tools are available:

- Screenshot Capture:

```bash
python tools/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
```

- LLM Verification with Images:

```bash
python tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
```

Example workflow:

```python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

# Take a screenshot
screenshot_path = take_screenshot_sync('https://example.com', 'screenshot.png')

# Verify with LLM
response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
```

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:

```bash
python ./tools/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
```

The LLM API supports multiple providers:

- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.

```bash
python ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```

This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.

```bash
python ./tools/search_engine.py "your search keywords"
```

This will output the search results in the following format:

```bash
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```

If needed, you can further use the `web_scraper.py` file to scrape the web page content.

## Lessons

### Core Lessons

- Use proper TypeScript types and interfaces for better type safety
- When adapting authentication systems, ensure proper session and user type compatibility
- Keep audit events consistent with the system's event types
- Handle rate limiting and security at the adapter level
- Implement proper error handling and audit logging
- Follow HIPAA compliance requirements for authentication and audit trails
- Make better use of available Python tools for research and automation:
  - Use search_engine.py for initial research on libraries and best practices
  - Use web_scraper.py for gathering detailed documentation
  - Use llm_api.py for analyzing complex technical decisions
  - Combine tools for a more thorough research workflow

### Recent Fixes

- Fixed PocketBase adapter type issues:
  - Moved PocketBase-specific interfaces to the adapter file
  - Updated audit event types to match system requirements
  - Fixed session user initialization
  - Improved type safety in authentication flow
  - Added proper error handling and audit logging

- Improved research workflow:
  - Started using search_engine.py more consistently
  - Combined search results with web_scraper.py for deeper analysis
  - Better utilization of Python toolkit for research tasks

## Scratchpad

### Current Task: Performance and Scalability Implementation

Progress:
[~] Large-Scale Deployment Optimization
  [X] Redis Caching Implementation
    [X] Design caching strategy
    [X] Switch to Upstash Redis
    [X] Implement cache invalidation
    [X] Add cache monitoring
  [ ] Database Optimization
    [ ] Analyze current query patterns
    [ ] Design indexing strategy
    [ ] Implement query optimizations
    [ ] Add performance monitoring
  [ ] Connection Management
    [ ] Implement connection pooling
    [ ] Add connection monitoring
    [ ] Set up load balancing
    [ ] Configure auto-scaling

[X] Progressive Enhancement
  [X] Service Worker Implementation
    [X] Create service worker configuration
    [X] Implement caching strategies
    [X] Add offline support
    [X] Add background sync
    [X] Add push notifications
  [X] Asset Optimization
    [X] Create offline fallback page
    [X] Implement service worker registration
    [X] Add offline indicator component
    [X] Add update notification system
  [X] Progressive Loading
    [X] Implement cache-first strategy for assets
    [X] Add network-first strategy for API calls
    [X] Create periodic sync for content
    [X] Add cleanup strategies

[ ] Monitoring Setup
  [ ] OpenTelemetry Integration
    [ ] Set up tracing infrastructure
    [ ] Add custom metrics
    [ ] Implement logging
  [ ] Error Tracking
    [ ] Set up Sentry
    [ ] Add error boundaries
    [ ] Implement alert rules

### Implementation Strategy

1. Database Optimization
   - Analyze current database usage patterns
   - Design and implement indexing strategy
   - Set up query monitoring
   - Add connection pooling

2. Monitoring Infrastructure
   - Set up OpenTelemetry
   - Implement error tracking
   - Add performance monitoring
   - Create dashboards

### Current Focus: Database Optimization

Next immediate steps:

1. Analyze current database usage patterns
2. Design indexing strategy
3. Implement query optimizations
4. Add performance monitoring

### Lessons Learned

- Use Upstash for Redis in production for better scalability
- Implement comprehensive service worker strategies for offline support
- Add proper monitoring and metrics collection
- Consider both performance and user experience in feature implementation

## Lessons Untold

### Core Lessons Learned

- Performance optimization requires careful measurement and monitoring
- Cache invalidation needs thorough planning
- Always measure before and after optimizations
- Consider scalability implications of all changes

### Best Practices

- Use appropriate caching strategies for different data types
- Implement proper monitoring from the start
- Follow progressive enhancement principles
- Consider both vertical and horizontal scaling
