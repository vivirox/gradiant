# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

## Tools

Note all the tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

IMPORTANT: Make better use of the available Python tools! Before diving into implementation, always try to:

1. Use search_engine.py to research solutions and best practices
2. Use web_scraper.py to gather detailed documentation
3. Use llm_api.py for complex analysis tasks
4. Combine tools for a better research workflow

Remember: These tools are here to help make better informed decisions. Use them proactively!

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following tools are available:

- Screenshot Capture:

```bash
python tools/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
```

- LLM Verification with Images:

```bash
python tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
```

Example workflow:

```python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

# Take a screenshot
screenshot_path = take_screenshot_sync('https://example.com', 'screenshot.png')

# Verify with LLM
response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
```

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:

```bash
python ./tools/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
```

The LLM API supports multiple providers:

- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.

```bash
python ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```

This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.

```bash
python ./tools/search_engine.py "your search keywords"
```

This will output the search results in the following format:

```bash
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```

If needed, you can further use the `web_scraper.py` file to scrape the web page content.

## Lessons

### Core Lessons

- Use proper TypeScript types and interfaces for better type safety
- When adapting authentication systems, ensure proper session and user type compatibility
- Keep audit events consistent with the system's event types
- Handle rate limiting and security at the adapter level
- Implement proper error handling and audit logging
- Follow HIPAA compliance requirements for authentication and audit trails
- Make better use of available Python tools for research and automation:
  - Use search_engine.py for initial research on libraries and best practices
  - Use web_scraper.py for gathering detailed documentation
  - Use llm_api.py for analyzing complex technical decisions
  - Combine tools for a more thorough research workflow

### Recent Fixes

- Fixed PocketBase adapter type issues:
  - Moved PocketBase-specific interfaces to the adapter file
  - Updated audit event types to match system requirements
  - Fixed session user initialization
  - Improved type safety in authentication flow
  - Added proper error handling and audit logging

- Improved research workflow:
  - Started using search_engine.py more consistently
  - Combined search results with web_scraper.py for deeper analysis
  - Better utilization of Python toolkit for research tasks

- Fixed PostgreSQL statistics views and column names:
  - Use pg_stat_user_tables for table statistics (n_live_tup, n_dead_tup, etc.)
  - Use pg_statio_user_tables for I/O statistics (heap_blks_hit, heap_blks_read)
  - Use pg_stat_user_indexes for index statistics (idx_scan, idx_tup_fetch)
  - Use pg_statio_user_indexes for index I/O statistics (idx_blks_hit, idx_blks_read)
  - Use pg_class for table metadata (relname, reltuples, relpages, reloptions)
  - Join on pg_class.oid = pg_stat_user_tables.relid for correct table matching

### Best Practices

- Use appropriate caching strategies for different data types
- Implement proper monitoring from the start
- Follow progressive enhancement principles
- Consider both vertical and horizontal scaling
- Use correct PostgreSQL system catalog views and column names for statistics gathering
- Properly handle table and index statistics for performance monitoring
- Use appropriate joins between system catalog tables for accurate metadata

## Scratchpad

### Current Task: Blockchain Audit Implementation

Progress:
[X] Blockchain Audit Implementation
  [X] Core Blockchain Service
    [X] Implement block structure
    [X] Add proof of work
    [X] Create Merkle tree integration
    [X] Add operation verification
    [X] Implement chain validation
  [X] Merkle Tree Implementation
    [X] Create tree structure
    [X] Add proof generation
    [X] Implement verification
    [X] Handle edge cases
    [X] Add test coverage
  [X] Enhanced ZK Audit Service
    [X] Create audit record structure
    [X] Implement blockchain integration
    [X] Add proof verification
    [X] Handle concurrent operations
    [X] Add comprehensive testing
  [X] Testing & Validation
    [X] Unit tests for MerkleTree
    [X] Tests for BlockchainAuditService
    [X] Tests for EnhancedZKAuditService
    [X] Concurrent operation tests
    [X] Tamper detection tests

### Completed Tasks:
1. Implemented MerkleTree with proof generation and verification
2. Created BlockchainAuditService with mining and chain validation
3. Developed EnhancedZKAuditService with comprehensive audit trails
4. Added extensive test coverage for all components
5. Successfully handled concurrent operations and tamper detection

### Lessons Learned:
- Proper singleton cleanup is crucial for testing
- Merkle tree state should be managed carefully between operations
- Caching Merkle trees with blocks improves verification efficiency
- Proper error handling and logging is essential for debugging
- Concurrent operations require careful state management
- Tamper detection needs comprehensive hash verification

### Best Practices:
- Cache Merkle trees with blocks to avoid regeneration
- Use proper cleanup in tests to avoid state interference
- Implement comprehensive logging for debugging
- Handle edge cases in proof generation and verification
- Maintain proper state management for concurrent operations

### Recent Fixes:
- Fixed Merkle tree management in BlockchainAuditService
- Improved proof generation and verification
- Enhanced concurrent operation handling
- Added proper singleton cleanup in tests
- Implemented better error handling and logging

### Next Steps:
1. Consider implementing:
   - Distributed consensus mechanism
   - Advanced tamper detection
   - Performance optimizations
   - Automated maintenance tasks
   - Advanced monitoring

2. Potential Enhancements:
   - Add support for pruning old blocks
   - Implement advanced caching strategies
   - Add performance benchmarking
   - Create monitoring dashboard
   - Add automated alerts

## Lessons

### Core Lessons

- Use proper monitoring from the start
- Track query performance metrics
- Analyze query patterns regularly
- Implement proper maintenance tasks
- Handle database scaling appropriately

### Recent Fixes

- Implemented comprehensive database monitoring
- Added query pattern analysis
- Created performance optimization tools
- Set up maintenance tasks
- Added detailed performance reporting

### Best Practices

- Monitor database performance continuously
- Track query patterns and performance
- Implement proper maintenance tasks
- Use appropriate indexes
- Follow PostgreSQL best practices
- Handle scaling appropriately
- Use proper monitoring metrics
- Implement automated maintenance
- Track performance metrics
- Use appropriate tools for analysis
